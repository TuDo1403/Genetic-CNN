{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_length_of(nodes):\n",
    "    return (nodes * (nodes - 1)) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  keras.layers import  Conv2D, BatchNormalization, Activation, Add, Flatten, Dense, Dropout, MaxPool2D, AveragePooling2D\n",
    "import keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(X, num_f, k_size):\n",
    "    node = X\n",
    "    node = Conv2D(filters=num_f, kernel_size=k_size,\n",
    "                  strides=(1, 1), padding='same')(node)\n",
    "    node = BatchNormalization(axis=3)(node)\n",
    "    node = Activation('relu')(node)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_something(X, code, num_nodes, num_f, k_size):\n",
    "    a0 = conv_layer(X, num_f, k_size)\n",
    "    nodes = {'a1': conv_layer(a0, num_f, k_size)}\n",
    "\n",
    "    for node in range(2, num_nodes + 1):\n",
    "        nodes['a' + str(node)] = a0\n",
    "        end_idx = code_length_of(node)\n",
    "        start_idx = end_idx - (node - 1)\n",
    "        prev_nodes = code[start_idx: end_idx]\n",
    "        connected_nodes = np.where(prev_nodes == 1)[0] + 1  # increment index number\n",
    "        for prev_node in connected_nodes:\n",
    "            if (prev_node == node-1):\n",
    "                nodes['a' + str(node)] = conv_layer(nodes['a' + str(node - 1)],\n",
    "                                                    num_f, k_size)\n",
    "            else:\n",
    "                nodes['a' + str(node)] = Add()([nodes['a' + str(node)],\n",
    "                                                nodes['a' + str(prev_node)]])\n",
    "\n",
    "    # Get node last\n",
    "    node_L = conv_layer(nodes['a' + str(num_nodes)], num_f, k_size)\n",
    "    return node_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_model(architecture, hyper_params,\n",
    "                  input_shape=(32, 32, 3), classes=1):\n",
    "    Pool = MaxPool2D if hyper_params['pooling'] == 'max' else AveragePooling2D\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "    X = X_input\n",
    "\n",
    "    stages = architecture['stages']\n",
    "    stage_name, nodes = stages[0]\n",
    "    end_idx = code_length_of(nodes)\n",
    "    code = architecture['code'][:end_idx]\n",
    "    X = do_something(X, code, nodes, hyper_params['filters'],\n",
    "                     hyper_params['kernel size'])\n",
    "    X = Pool(pool_size=hyper_params['pool size'],\n",
    "                 strides=hyper_params['strides'], padding='valid')(X)\n",
    "    for i in range(1, len(stages)):\n",
    "        stage_name, nodes = stages[i]\n",
    "        start_idx = code_length_of(stages[i - 1][1])\n",
    "        end_idx = start_idx + code_length_of(nodes)\n",
    "        code = architecture['code'][start_idx: end_idx]\n",
    "        X = do_something(X, code, nodes, hyper_params['filters'] * (i + 1),\n",
    "                         hyper_params['kernel size'])\n",
    "        X = Pool(pool_size=hyper_params['pool size'],\n",
    "                 strides=hyper_params['strides'], padding='valid')(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(hyper_params['fc units'], activation='relu')(X)\n",
    "    X = Dropout(hyper_params['drop out'])(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "\n",
    "    # Create model\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=hyper_params['optimizer'], metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = { 'stages' : [('Stage1', 3), ('Stage2', 5)], \n",
    "                 'code' : np.array([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1]),\n",
    "                }\n",
    "hyper_params = { 'optimizer' : 'adam',\n",
    "                 'drop out' : 0.5,\n",
    "                 'epochs' : 20,\n",
    "                 'kernel size' : (5, 5),\n",
    "                 'pool size' : 2,\n",
    "                 'strides' : 2,\n",
    "                 'filters' : 20,\n",
    "                 'fc units': 500,\n",
    "                 'pooling' : 'max'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genetic_model(architecture, hyper_params,\n",
    "                     input_shape=x_train.shape[1:], classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the logs in a timestamped subdirectory\n",
    "# This allows to easy select different training runs\n",
    "# In order not to overwrite some data, it is useful to have a name with a timestamp\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Specify the callback object\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# tf.keras.callback.TensorBoard ensures that logs are created and stored\n",
    "# We need to pass callback object to the fit method\n",
    "# The way to do this is by passing the list of callback objects, which is in our case just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 20)   1520        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 20)   80          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 20)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 20)   10020       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 20)   80          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 20)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 20)   10020       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 20)   80          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 20)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 20)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 40)   20040       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 40)   160         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 40)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 40)   40040       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 40)   160         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 40)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 40)   0           activation_13[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 40)   40040       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 40)   160         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 40)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 40)   40040       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 40)   160         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 40)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 40)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2560)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          1280500     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           5010        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,448,110\n",
      "Trainable params: 1,447,670\n",
      "Non-trainable params: 440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 1.6900 - accuracy: 0.3884 - val_loss: 1.7006 - val_accuracy: 0.4501\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.2354 - accuracy: 0.5611 - val_loss: 1.0882 - val_accuracy: 0.6163\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.0134 - accuracy: 0.6459 - val_loss: 1.0557 - val_accuracy: 0.6295\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.8798 - accuracy: 0.6955 - val_loss: 0.9473 - val_accuracy: 0.6773\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7827 - accuracy: 0.7335 - val_loss: 0.9619 - val_accuracy: 0.6663\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7083 - accuracy: 0.7588 - val_loss: 1.0449 - val_accuracy: 0.6665\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.6385 - accuracy: 0.7836 - val_loss: 0.7011 - val_accuracy: 0.7668\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5838 - accuracy: 0.8005 - val_loss: 0.7057 - val_accuracy: 0.7626\n",
      "Epoch 9/20\n",
      "1265/1563 [=======================>......] - ETA: 5s - loss: 0.5308 - accuracy: 0.8175"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y=y_train, \n",
    "          epochs=20, \n",
    "          validation_data=(x_test, y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5468), started 0:38:11 ago. (Use '!kill 5468' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4c9284202ca7442a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4c9284202ca7442a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tf_gpu': conda)",
   "language": "python",
   "name": "python38364bittfgpucondaabea35000e4642b2ba9804f0975f02c3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
